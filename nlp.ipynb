{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:21:24.341161Z",
     "start_time": "2024-07-29T09:21:24.335447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import re"
   ],
   "id": "7e0c909f3c0999c3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Authors: Netanel Shen, Gadi Yohanan\n",
    "\n",
    "Introduction\n",
    "This is a a project by Netanel Shen and Gadi Yohannan, where we attempt to train a model to recognize whether a certain article is real of fake.\n",
    "in the 'dataset' folder we have CSV files with urls leading to real and fake articles (we took the dataset from a github repo).\n",
    "\n",
    "## Answers\n",
    "\n",
    "    1. we can ensure the data's quality because it's a known and tested repository, because it's extremly popular we assume it's also credible.\n",
    "\n",
    "## Step 1: Define Functions\n",
    "\n",
    "We start by defining two functions:\n",
    "1. `fetch_article_content(url)`: This function fetches the content of an article from a given URL.\n",
    "2. `process_articles(file_path, output_folder, max_articles)`: This function processes articles from a CSV file and stores their content in the specified output folder."
   ],
   "id": "916b40cc6d841705"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3bb0dfd914e58d3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:21:26.998335Z",
     "start_time": "2024-07-29T09:21:26.991080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch article content function\n",
    "def fetch_article_content(url):\n",
    "    \"\"\"Fetch article content from a URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            paragraphs = soup.find_all('p')\n",
    "            content = ' '.join([para.get_text() for para in paragraphs])\n",
    "            return content\n",
    "        else:\n",
    "            return None\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n"
   ],
   "id": "53b5bb44e9685ddb",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:21:28.084559Z",
     "start_time": "2024-07-29T09:21:28.075949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_articles(file_path, output_folder, max_articles):\n",
    "    \"\"\"Process articles from a CSV file and store content.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'news_url' not in df.columns:\n",
    "        print(f\"No 'news_url' column in {file_path}\")\n",
    "        return\n",
    "\n",
    "    # Determine if the article is fake or real based on the filename\n",
    "    category = 'fake' if 'fake' in file_path.lower() else 'real'\n",
    "    output_folder = os.path.join(output_folder, category)\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if count >= max_articles:\n",
    "            break\n",
    "\n",
    "        url = row['news_url']\n",
    "        content = fetch_article_content(url)\n",
    "        if content:\n",
    "            output_file = os.path.join(output_folder, f'article_{os.path.basename(file_path)}_{idx}.txt')\n",
    "            with open(output_file, 'w', encoding='utf-8') as file:\n",
    "                file.write(content)\n",
    "            print(f\"Processed article {idx} from {file_path} into {category} category\")\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"Failed to fetch content from {url}\")\n"
   ],
   "id": "59d44c44d7c1218e",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define the Article Processing Function\n",
    "\n",
    "Next, we define the `process_articles` function. This function:\n",
    "- Reads a CSV file containing URLs of news articles.\n",
    "- Categorizes the articles as 'fake' or 'real' based on the filename.\n",
    "- Creates output directories for storing the processed articles.\n",
    "- Fetches the content of each article and saves it as a text file in the appropriate folder.\n",
    "\n",
    "## Step 3: Specify Input Files and Output Folder\n",
    "\n",
    "We now specify the CSV files containing the article URLs and the folder where the processed articles will be saved.\n"
   ],
   "id": "35b91a62bddacf31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:21:31.843697Z",
     "start_time": "2024-07-29T09:21:31.838785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "csv_files = [\n",
    "    'dataset/gossipcop_fake.csv',\n",
    "    'dataset/gossipcop_real.csv',\n",
    "    'dataset/politifact_fake.csv',\n",
    "    'dataset/politifact_real.csv'\n",
    "]\n",
    "\n",
    "# Output folder for articles\n",
    "output_folder = 'cleaned_articles'\n",
    "\n",
    "# Maximum number of articles to process per file\n",
    "max_articles = 100\n"
   ],
   "id": "a9e838905bbf172b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Process Each CSV File\n",
    "\n",
    "Finally, we process each CSV file using the `process_articles` function. The content of the articles will be fetched, categorized, and saved as text files in the specified output folder.\n"
   ],
   "id": "6f1d86325ed0d73f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for csv_file in csv_files:\n",
    "    process_articles(csv_file, output_folder, max_articles)"
   ],
   "id": "17d885dc667e3cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Load and clean the data\n",
    "Next, we load and clean the data from the 'fake' and 'real' article folders. We use a function `clean_text` to remove stopwords, punctuation, and perform lemmatization using spaCy.\n",
    "## Answers:\n",
    "    2. in this step, we clean the data.\n",
    "    * Punctuation Removal - same thing, reduce noise.\n",
    "    * HTML tags removal - this is irrelevant to our data processing.\n",
    "    * Special Characters removal - reduce noise\n",
    "    * We also take care of null / NaN values by deleting them.\n",
    "    \n",
    "    3. Lowercasing - consistency in unique tokens.\n",
    "    4. Lemmatization - reducing words to base form, reduces the number of unique tokens.\n",
    "    5. Remove stop words is important because it reduces noise in the data, it adds additional data but no real information.\n",
    "\n",
    "\n",
    "      \n"
   ],
   "id": "58a70a5b05c5751f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:23:33.043087Z",
     "start_time": "2024-07-29T09:21:37.450578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define the paths to the fake and real articles\n",
    "fake_path = 'cleaned_articles/fake'\n",
    "real_path = 'cleaned_articles/real'\n",
    "\n",
    "# Function to clean and lemmatize text using spaCy\n",
    "def clean_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    cleaned_text = re.sub(r'<.*?>', '', cleaned_text)  # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', cleaned_text)  # Remove special characters\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remove extra whitespace\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# Load data from folder\n",
    "def load_data_from_folder(folder, label):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        with open(os.path.join(folder, filename), 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            cleaned_text = clean_text(text)\n",
    "            data.append((cleaned_text, label))\n",
    "    return data\n",
    "\n",
    "# Load fake and real data\n",
    "fake_data = load_data_from_folder(fake_path, 'FAKE')\n",
    "real_data = load_data_from_folder(real_path, 'REAL')\n",
    "\n",
    "# Combine data into a single DataFrame\n",
    "all_data = fake_data + real_data\n",
    "df = pd.DataFrame(all_data, columns=['text', 'label'])\n",
    "\n",
    "# Ensure no NaN values are present\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "# Save to a single CSV file\n",
    "df.to_csv('cleaned_articles.csv', index=False)\n"
   ],
   "id": "a57c9350147310a3",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 6: Load Combined Data\n",
    "\n",
    "We save the cleaned data into a CSV file and then load it back into a DataFrame. We ensure there are no NaN values in the text column.\n"
   ],
   "id": "672d06133ed2a0d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:37:59.193996Z",
     "start_time": "2024-07-29T09:37:59.164193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the combined CSV file\n",
    "df = pd.read_csv('cleaned_articles.csv')\n",
    "\n",
    "# Ensure no NaN values in the text column\n",
    "df['text'].fillna('', inplace=True)\n"
   ],
   "id": "5584ff439631f316",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 7: Split Data into Training and Test Sets\n",
    "\n",
    "We split the data into training and test sets. This will allow us to train our models on the training set and evaluate their performance on the test set.\n"
   ],
   "id": "c2e4b03fc26025e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:38:02.142297Z",
     "start_time": "2024-07-29T09:38:02.136438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)\n"
   ],
   "id": "9fd5bf177edbe2d1",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 8: Define and Train Models\n",
    "\n",
    "We define several models and train them using a pipeline that includes a TF-IDF vectorizer and the classifier. We evaluate each model and print a classification report.\n",
    "\n",
    "## Answers\n",
    "    6. We are using scikit-Learn's pipeline class which allows to combine multiple processing steps. First, we use 'TfidVectorizer' for text vectorization and the classification models. We are converting the text into a numerical format before feeding it to the classifier.\n",
    "    7. To ensure a fair split, the provided code uses train_test_split from Scikit-Learn to divide the data into training and testing sets. This function randomly splits the data based on the specified test_size parameter (20% for testing in this case) and a random_state to ensure reproducibility. This approach helps to maintain a representative sample in both the training and testing sets, reducing the risk of overfitting and ensuring the model's performance is evaluated on unseen data.\n",
    "    8. Naive Bayes:\n",
    "    Advantages: Simple, fast, works well with high-dimensional data, particularly effective for text classification.\n",
    "    Disadvantages: Assumes independence among features, which is rarely true in practice.\n",
    "    Random Forest:\n",
    "    \n",
    "    Advantages: Robust to overfitting, handles large datasets well, provides feature importance.\n",
    "    Disadvantages: Can be slow and resource-intensive for large datasets, less interpretable than simpler models.\n",
    "    Support Vector Machine (SVM):\n",
    "    \n",
    "    Advantages: Effective in high-dimensional spaces, works well with clear margin of separation.\n",
    "    Disadvantages: Computationally expensive, less effective on large datasets, sensitive to the choice of kernel and parameters.\n",
    "    K-Nearest Neighbors (KNN):\n",
    "    \n",
    "    Advantages: Simple, intuitive, no training phase.\n",
    "    Disadvantages: Computationally expensive during prediction, sensitive to the choice of K and distance metric, struggles with high-dimensional data.\n",
    "    Logistic Regression:\n",
    "    \n",
    "    Advantages: Simple, interpretable, works well for binary classification, less prone to overfitting.\n",
    "    Disadvantages: Assumes linear relationship between features and the log-odds, less effective with complex relationships.\n",
    "\n"
   ],
   "id": "dadcb0ae10c6e441"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Answer:\n",
    "The following metrics were used to evaluate the models' performance:\n",
    "\n",
    "Precision: Measures the proportion of true positive predictions among all positive predictions made by the model.\n",
    "Recall: Measures the proportion of true positive predictions among all actual positive instances.\n",
    "F1 Score: The harmonic mean of Precision and Recall, providing a balance between the two."
   ],
   "id": "85052f4a248e9e59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:38:07.541547Z",
     "start_time": "2024-07-29T09:38:03.126148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the models\n",
    "models = [\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('SVM', SVC()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=300))\n",
    "]\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='REAL')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='REAL')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='REAL')\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Evaluate each model and store the results\n",
    "for name, model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', model),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    precision, recall, f1 = evaluate_model(pipeline, X_test, y_test)\n",
    "    results[name] = {'Precision': precision, 'Recall': recall, 'F1-Score': f1}\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "id": "5fca441867c5d902",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.09      0.16        35\n",
      "        REAL       0.63      1.00      0.77        55\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.82      0.54      0.47        90\n",
      "weighted avg       0.78      0.64      0.53        90\n",
      "\n",
      "--- Random Forest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.31      0.48        35\n",
      "        REAL       0.70      1.00      0.82        55\n",
      "\n",
      "    accuracy                           0.73        90\n",
      "   macro avg       0.85      0.66      0.65        90\n",
      "weighted avg       0.81      0.73      0.69        90\n",
      "\n",
      "--- SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.11      0.21        35\n",
      "        REAL       0.64      1.00      0.78        55\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.82      0.56      0.49        90\n",
      "weighted avg       0.78      0.66      0.56        90\n",
      "\n",
      "--- KNN ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.82      0.26      0.39        35\n",
      "        REAL       0.67      0.96      0.79        55\n",
      "\n",
      "    accuracy                           0.69        90\n",
      "   macro avg       0.74      0.61      0.59        90\n",
      "weighted avg       0.73      0.69      0.64        90\n",
      "\n",
      "--- Logistic Regression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       1.00      0.09      0.16        35\n",
      "        REAL       0.63      1.00      0.77        55\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.82      0.54      0.47        90\n",
      "weighted avg       0.78      0.64      0.53        90\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 9: Display Model Performance\n",
    "\n",
    "We create a DataFrame to display the performance of each model in terms of precision, recall, and F1-score.\n",
    "\n",
    "## Answers:\n",
    "    9. this is also the answer to question 9.\n"
   ],
   "id": "3c7e85ed449cbcf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:38:07.550641Z",
     "start_time": "2024-07-29T09:38:07.542552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n"
   ],
   "id": "22eedaa4feab3b92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Precision    Recall  F1-Score\n",
      "Naive Bayes           0.632184  1.000000  0.774648\n",
      "Random Forest         0.696203  1.000000  0.820896\n",
      "SVM                   0.639535  1.000000  0.780142\n",
      "KNN                   0.670886  0.963636  0.791045\n",
      "Logistic Regression   0.632184  1.000000  0.774648\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 10: Save the Best Model\n",
    "\n",
    "Answers:\n",
    "    10. We identify the best performing model to be the one with the highest F1 score - Random Forest. Though SVM and KNN were more consistend and also had pretty good F1 scores. We will save the RandomForest using 'pickle' into the file 'best_model.pkl',\n"
   ],
   "id": "3fb3ced316c8453d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:38:08.708125Z",
     "start_time": "2024-07-29T09:38:07.551650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "id": "bc5eb3445da53f0d",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 11: Predict on New Articles\n",
    "\n",
    "We define a function to clean and lemmatize new articles using spaCy, and then use the saved model to predict whether the new article is fake or real.\n"
   ],
   "id": "eb9336b5a7f39bf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T09:38:08.772060Z",
     "start_time": "2024-07-29T09:38:08.709479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to clean and lemmatize text using spaCy for new articles\n",
    "def clean_text_new_article(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    cleaned_text = re.sub(r'<.*?>', '', cleaned_text)  # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', cleaned_text)  # Remove special characters\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Remove extra whitespace\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# Example article for testing\n",
    "new_article = \"\"\"\n",
    "Hillary Clinton had a third and most likely fatal heart attack this afternoon after spending the morning being told she'd be getting better. It almost seems fitting that the last thing she hears is a lie about her own wellbeing. The Butcher of Benghazi will meet her maker, says Doctor Eugene Icsa of Westchester Memorial Hospital in upstate New York, as the damage to her heart is irreparable at this point. Secretary Clinton fought hard, but today her fight is over. We predict she'll be at rest within hours. The Clinton family has asked for privacy and wouldn't answer questions about whether or not they had to decide to pull the plug or if they're simply being told nothing can be done. Chelsea Clinton was seen entering the hospital in tears shortly after noon according to a new report from LLOD correspondent Skip Tetheluda. Chelsea came alone and was obviously distraught. She made no comment to the press but did stop to tell one photographer to have some respect while she visits a great woman for the last time. She hasn't come out and is presumably sitting and waiting to say goodbye. Bill Clinton is sitting on the front porch of the Chappaqua mansion drinking what looks like either tomato juice or a Bloody Mary. We'll update you as soon as we confirm that Clinton has gone on to answer for her crimes with an eternity in Hell.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the new article\n",
    "cleaned_article = clean_text_new_article(new_article)\n",
    "\n",
    "# Make prediction using the best model\n",
    "with open('best_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "prediction = model.predict([cleaned_article])\n",
    "print(\"Prediction for the new article:\", \"REAL\" if prediction[0] == 'REAL' else \"FAKE\")\n"
   ],
   "id": "993cf9fd713473e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the new article: REAL\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "54d555d34e7e6056"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
